{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J make_zarr\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=1\n",
      "#SBATCH --mem=112G\n",
      "#SBATCH -t 00:30:00\n",
      "#SBATCH --constraint=HSW24\n",
      "#SBATCH --exclusive\n",
      "#SBATCH --nodes=1\n",
      "#SBATCH --ntasks-per-node=1\n",
      "JOB_ID=${SLURM_JOB_ID%;*}\n",
      "\n",
      "\n",
      "\n",
      "/scratch/cnt0024/hmg2840/albert7a/anaconda3/bin/python -m distributed.cli.dask_worker tcp://172.30.100.4:46543 --nthreads 0 --nprocs 28 --memory-limit 4.29GB --name make_zarr--${JOB_ID}-- --death-timeout 60 --local-directory $SCRATCHDIR --interface ib0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/dashboard/core.py:74: UserWarning: \n",
      "Failed to start diagnostics server on port 8787. [Errno 13] Permission denied\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    }
   ],
   "source": [
    "from dask_jobqueue import SLURMCluster \n",
    "from dask.distributed import Client \n",
    "  \n",
    "cluster = SLURMCluster(cores=1,name='make_zarr',walltime='00:30:00',job_extra=['--constraint=HSW24','--exclusive','--nodes=1','--ntasks-per-node=1'],memory='120GB',interface='ib0') \n",
    "print(cluster.job_script()) \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>SLURMCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://172.30.100.4:46543\n",
       "  <li><b>Dashboard: </b><a href='http://172.30.100.4:44777/status' target='_blank'>http://172.30.100.4:44777/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://172.30.100.4:46543' processes=0 cores=0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import dask\n",
    "import zarr\n",
    "import numpy as np                                                                                        \n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/scheduler.py:313: UserWarning: WorkerState.ncores has moved to WorkerState.nthreads\n",
      "  warnings.warn(\"WorkerState.ncores has moved to WorkerState.nthreads\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 9.3 µs\n",
      "beginning month  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending month  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/scheduler.py:313: UserWarning: WorkerState.ncores has moved to WorkerState.nthreads\n",
      "  warnings.warn(\"WorkerState.ncores has moved to WorkerState.nthreads\")\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "compressor = zarr.Blosc(cname='zstd', clevel=3, shuffle=2)                                                \n",
    "\n",
    "m=7\n",
    "print('beginning month ',str(m))\n",
    "mm=str(m).zfill(2)\n",
    "if m > 6:\n",
    "    year=2009\n",
    "else:\n",
    "    year=2010\n",
    "ds=xr.open_mfdataset('/scratch/cnt0024/hmg2840/albert7a/eNATL60/eNATL60-BLB002-S/1h/surf/*'+str(year)+'m'+str(mm)+'*sozocrtx.nc', parallel=True, concat_dim='time_counter',chunks={'time_counter':672,'y':120,'x':120})\n",
    "\n",
    "encoding = {vname: {'compressor': compressor} for vname in ds.variables}\n",
    "ds.to_zarr(store='/scratch/cnt0024/hmg2840/albert7a/eNATL60/zarr/zarr_eNATL60-BLB002-SSU-1h-y'+str(year)+'m'+str(mm), encoding=encoding)\n",
    "print('ending month ',str(m))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:              (axis_nbounds: 2, time_counter: 744, x: 8354, y: 4729)\n",
       "Coordinates:\n",
       "    nav_lat              (y, x) float32 dask.array<shape=(4729, 8354), chunksize=(296, 1045)>\n",
       "    nav_lon              (y, x) float32 dask.array<shape=(4729, 8354), chunksize=(296, 1045)>\n",
       "    time_centered        (time_counter) datetime64[ns] dask.array<shape=(744,), chunksize=(744,)>\n",
       "  * time_counter         (time_counter) datetime64[ns] 2009-07-01T00:30:00 ... 2009-07-31T23:30:00\n",
       "Dimensions without coordinates: axis_nbounds, x, y\n",
       "Data variables:\n",
       "    sozocrtx             (time_counter, y, x) float32 dask.array<shape=(744, 4729, 8354), chunksize=(24, 120, 120)>\n",
       "    time_counter_bounds  (time_counter, axis_nbounds) datetime64[ns] dask.array<shape=(744, 2), chunksize=(744, 2)>\n",
       "Attributes:\n",
       "    Conventions:  CF-1.6\n",
       "    NCO:          4.4.6\n",
       "    TimeStamp:    07/01/2019 17:04:54 +0100\n",
       "    description:  ocean U grid variables\n",
       "    file_name:    eNATL60-BLB002_1h_20090630_20090704_gridU-2D_20090701-20090...\n",
       "    history:      Wed Jul 17 14:15:45 2019: ncks -O -F -v sozocrtx /store/CT1...\n",
       "    ibegin:       0\n",
       "    jbegin:       0\n",
       "    name:         /scratch/tmp/3735876/eNATL60-BLB002_1h_20090630_20090704_gr...\n",
       "    ni:           8354\n",
       "    nj:           9\n",
       "    timeStamp:    2018-Dec-30 14:12:24 GMT\n",
       "    title:        ocean U grid variables\n",
       "    uuid:         0a593c68-54ee-42d9-acc0-a60212ed838b"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/scheduler.py:313: UserWarning: WorkerState.ncores has moved to WorkerState.nthreads\n",
      "  warnings.warn(\"WorkerState.ncores has moved to WorkerState.nthreads\")\n"
     ]
    }
   ],
   "source": [
    "ds_z = xr.open_zarr('/scratch/cnt0024/hmg2840/albert7a/eNATL60/zarr/zarr_eNATL60-BLB002-SSU-1h-y2009m07')\n",
    "ds_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cnt0024/hmg2840/albert7a/anaconda3/lib/python3.7/site-packages/distributed/scheduler.py:313: UserWarning: WorkerState.ncores has moved to WorkerState.nthreads\n",
      "  warnings.warn(\"WorkerState.ncores has moved to WorkerState.nthreads\")\n"
     ]
    }
   ],
   "source": [
    "dsu=xr.open_zarr('/scratch/cnt0024/hmg2840/albert7a/eNATL60/zarr/zarr_eNATL60-BLB002-SSU-1h-y2009m07')\n",
    "lat=dsu['nav_lat']\n",
    "lon=dsu['nav_lon']\n",
    " \n",
    "latmin = 40.0; latmax = 45.0;\n",
    "lonmin = -40.0; lonmax = -35.0;\n",
    "\n",
    "domain = (lonmin<lon) * (lon<lonmax) * (latmin<lat) * (lat<latmax)\n",
    "where = np.where(domain)\n",
    "\n",
    "#get indice\n",
    "jmin = np.min(where[0][:])\n",
    "jmax = np.max(where[0][:])\n",
    "imin = np.min(where[1][:])\n",
    "imax = np.max(where[1][:])\n",
    "\n",
    "latbox=lat[jmin:jmax,imin:imax]\n",
    "lonbox=lon[jmin:jmax,imin:imax]\n",
    "u=dsu['sozocrtx'][:,jmin:jmax,imin:imax]\n",
    "check_NaN = (1*np.isnan(u.values)).sum()\n",
    "print(check_NaN)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
